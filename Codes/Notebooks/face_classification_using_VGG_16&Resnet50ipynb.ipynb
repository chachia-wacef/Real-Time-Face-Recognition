{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "face_classification_using_VGG.16&Resnet50ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "CF0YnF0iu73R"
      },
      "source": [
        "#Connect to Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrlE6k8GvozQ"
      },
      "source": [
        "!mkdir /content/data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sg9kgi62u9hQ"
      },
      "source": [
        "!cp -r /content/gdrive/MyDrive/Faces_Data/* /content/data ##"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rxn18kIeu9am"
      },
      "source": [
        "!cp -r /content/gdrive/MyDrive/Models/* /content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9tVnIDVvDTa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "3be06c09bd16cc29a775672cba60360e93f90409",
        "id": "iTsO3o8ZuMPB"
      },
      "source": [
        "data_dir = '/content/data'\n",
        "vgg16weight = '/content/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "resnet50weight = '/content/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "3c048e92155dbdf3ac117465021bcb12b511a1f8",
        "scrolled": false,
        "id": "phfhgZQcuMPH"
      },
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from keras.optimizers import RMSprop, SGD\n",
        "from keras import backend as K\n",
        "\n",
        "import keras\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "85628d9635634229bd8712d9a986415385d48bb6",
        "id": "asR83vhsuMPJ"
      },
      "source": [
        "### 1. Prepare Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "aa0c9ecd43c4828b2a714948d3478c67383a9bda",
        "collapsed": true,
        "id": "S8CpEe6TuMPL"
      },
      "source": [
        "img_width, img_height = 224, 224  ###\n",
        "\n",
        "train_data_dir = os.path.join(data_dir, 'train')\n",
        "validation_data_dir = os.path.join(data_dir, 'val')\n",
        "\n",
        "nb_train_samples = 93 ##\n",
        "nb_validation_samples = 25  ##\n",
        "epochs = 50\n",
        "batch_size = 16\n",
        "numclasses = 2 ###"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "f9f680ed21e84ed9cbbb4464a2ad4ff2cdc98f5b",
        "scrolled": true,
        "id": "T84ClrU8uMPN"
      },
      "source": [
        "# this is the augmentation configuration we will use for training\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1. / 255,\n",
        "    rotation_range=10,  \n",
        "    zoom_range = 0.1, \n",
        "    width_shift_range=0.1,  \n",
        "    height_shift_range=0.1, \n",
        "    #shear_range=0.2,\n",
        "    vertical_flip=False,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "# this is the augmentation configuration we will use for testing:\n",
        "# only rescaling\n",
        "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "b6005e3cf37b715831e5112e2f69e4e8f40d4c3d",
        "id": "8JgIqkRouMPQ"
      },
      "source": [
        "### 2. Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "d40ddf608386f6c1d2d4b1af4e0a6614e76d0a75",
        "id": "CXNRnCVLuMPT"
      },
      "source": [
        "if K.image_data_format() == 'channels_first':\n",
        "    input_shape = (3, img_width, img_height)\n",
        "else:\n",
        "    input_shape = (img_width, img_height, 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "53895b45df5d332dc364b3d9b0b058d28889de52",
        "collapsed": true,
        "id": "smDMM9kduMPW"
      },
      "source": [
        "def vgg16CNNtl(input_shape, outclass, sigma='sigmoid'):\n",
        "    \n",
        "    base_model = None\n",
        "    base_model = keras.applications.VGG16(weights=None, include_top=False, input_shape=input_shape)\n",
        "    base_model.load_weights(vgg16weight)\n",
        "        \n",
        "    top_model = Sequential()\n",
        "    top_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
        "    for i in range(2):\n",
        "        top_model.add(Dense(4096, activation='relu'))\n",
        "        top_model.add(Dropout(0.5))\n",
        "    top_model.add(Dense(outclass, activation=sigma))\n",
        "\n",
        "    model = None\n",
        "    model = Model(inputs=base_model.input, outputs=top_model(base_model.output))\n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQdiIubO0nOm"
      },
      "source": [
        "def resnet50tl(input_shape, outclass, sigma='sigmoid'):\n",
        "    \n",
        "    base_model = None\n",
        "    base_model = keras.applications.resnet50.ResNet50(weights=None, include_top=False, input_shape=input_shape)\n",
        "    base_model.load_weights(resnet50weight)\n",
        "    \n",
        "    top_model = Sequential()\n",
        "    top_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
        "    for i in range(2):\n",
        "        top_model.add(Dense(4096, activation='relu'))\n",
        "        top_model.add(Dropout(0.5))\n",
        "    top_model.add(Dense(outclass, activation=sigma))\n",
        "\n",
        "    model = None\n",
        "    model = Model(inputs=base_model.input, outputs=top_model(base_model.output))\n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "d2434d17467a68ab77b8230cef39afc09e63f15c",
        "collapsed": true,
        "id": "ir7F_XBGuMPZ"
      },
      "source": [
        "model = resnet50tl(input_shape, numclasses, 'softmax')\n",
        "lr = 1e-5\n",
        "decay = 1e-7 #0.0\n",
        "optimizer = RMSprop(lr=lr, decay=decay)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizer,\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "dd22fe68f3571da784c2e71cc40999b25d0b319a",
        "id": "XwlSO-IcuMPa"
      },
      "source": [
        "### 3. Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "scrolled": false,
        "_uuid": "eb679a663f86cfcd737ef9413c469826c5f72a15",
        "id": "To2mOabduMPa"
      },
      "source": [
        "history = model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=nb_train_samples // batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=nb_validation_samples // batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "4d0b0f3e58ae0b0901b09353d3f1b0a9db15a598",
        "id": "wmMxwZ2XuMPc"
      },
      "source": [
        "# Get training and test loss histories\n",
        "training_loss = history.history['loss']\n",
        "training_acc = history.history['acc']\n",
        "\n",
        "# Create count of the number of epochs\n",
        "epoch_count = range(1, len(training_loss) + 1)\n",
        "\n",
        "fig=plt.figure(figsize=(12, 4))\n",
        "# Visualize loss history\n",
        "fig.add_subplot(121)\n",
        "plt.plot(epoch_count, training_loss, 'r--')\n",
        "plt.plot(epoch_count, training_acc, 'b-')\n",
        "plt.legend(['Training Loss', 'Training Accuracy'])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Training Loss/Acc')\n",
        "\n",
        "# Get training and test loss histories\n",
        "val_acc = history.history['val_acc']\n",
        "training_acc = history.history['acc']\n",
        "\n",
        "# Create count of the number of epochs\n",
        "epoch_count = range(1, len(val_acc) + 1)\n",
        "\n",
        "# Visualize loss history\n",
        "fig.add_subplot(122)\n",
        "plt.plot(epoch_count, val_acc, 'r--')\n",
        "plt.plot(epoch_count, training_acc, 'b-')\n",
        "plt.legend(['Validation Accuracy', 'Training Accuracy'])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "8f3d0837aed7284b7024c38f77137bbe82ad8c2f",
        "id": "sEqPU39VuMPf"
      },
      "source": [
        "saveweight =  'celebriytag_weight.h5'\n",
        "model.save_weights(saveweight)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "374258d36b7b06bb4a0201b87e8f82e219ccb24b",
        "id": "NWXB6NvVuMPh"
      },
      "source": [
        "### 4. Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "ec07fed520e584354e32b5f38a27a99ce83b43be",
        "id": "UgqH0qdpuMPh"
      },
      "source": [
        "from keras.preprocessing import image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import cv2\n",
        "import requests\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "32fa9768fc8b66a9607e8e7bc406d2bd18b7b150",
        "scrolled": true,
        "id": "1l0YTH2quMPi"
      },
      "source": [
        "labels = ['ben_afflek',  'elton_john',  'jerry_seinfeld',  'madonna',  'mindy_kaling']\n",
        "test_imgs = ['ben_afflek/httpabsolumentgratuitfreefrimagesbenaffleckjpg.jpg']\n",
        "\n",
        "for test in test_imgs:\n",
        "    test_img = os.path.join(validation_data_dir, test)\n",
        "    img = image.load_img(test_img, target_size=(img_width, img_height))\n",
        "    x = image.img_to_array(img)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    x /= 255.\n",
        "    classes = model.predict(x)\n",
        "    result = np.squeeze(classes)\n",
        "    result_indices = np.argmax(result)\n",
        "    \n",
        "    img = cv2.imread(test_img, cv2.IMREAD_COLOR)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    plt.axis('off')\n",
        "    plt.title(\"{}, {:.2f}%\".format(labels[result_indices], result[result_indices]*100))\n",
        "    plt.imshow(img)\n",
        "    \n",
        "    #print(\"{}, {:.2f}%\".format(labels[result_indices], result[result_indices]*100))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}